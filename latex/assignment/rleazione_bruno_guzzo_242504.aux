\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vaswani2023attentionneed}
\citation{veličković2018graphattentionnetworks}
\citation{vaswani2023attentionneed}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Graph Attention}{1}{section.2}\protected@file@percent }
\newlabel{graph_attention}{{2}{1}{Graph Attention}{section.2}{}}
\citation{veličković2018graphattentionnetworks}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.1}Graph Attention Layer}{2}{subsubsection.2.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.2}Feature Transformation}{2}{subsubsection.2.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.3}Attention Mechanism}{2}{subsubsection.2.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.4}Masked Attention}{2}{subsubsection.2.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.5}Normalization}{2}{subsubsection.2.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.6}Feature Aggregation}{3}{subsubsection.2.0.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.7}Multi-Head Attention}{3}{subsubsection.2.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.8}Concatenation}{3}{subsubsection.2.0.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.9}Averaging}{3}{subsubsection.2.0.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Wikipedia Articles Link Dataset}{3}{section.3}\protected@file@percent }
\citation{reimers-2019-sentence-bert}
\citation{wang2020minilmdeepselfattentiondistillation}
\citation{devlin2019bertpretrainingdeepbidirectional}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Figure 1: A graph of 2000 nodes built form the root article title 'Sustainability'.}}{4}{figure.caption.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Graph Extraction Algorithm}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Node Embedding}{4}{subsection.3.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Wikipedia Graph Extraction using BFS}}{5}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg_1}{{1}{5}{Wikipedia Graph Extraction using BFS}{algorithm.1}{}}
\citation{veličković2018graphattentionnetworks}
\citation{kipf2017semisupervisedclassificationgraphconvolutional}
\citation{vaswani2023attentionneed}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Final Dataset}{6}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Graph Neural Network Architecture}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Network Architecture In Detail}{7}{subsection.4.1}\protected@file@percent }
\newlabel{figure_2}{{\caption@xref {figure_2}{ on input line 194}}{7}{Network Architecture In Detail}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Figure 2: Graphical representation of the our final \textbf  {graph neural network}.}}{7}{figure.caption.2}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{papers.bib}
\bibcite{devlin2019bertpretrainingdeepbidirectional}{{1}{2019}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Chosen Architecture Parameters}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Network Training}{8}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Link Prediction Task Results}{8}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Methodology}{8}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Results/Findings}{8}{section.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table 1: Description of your table.}}{8}{table.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Discussion}{8}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Conclusion}{8}{section.10}\protected@file@percent }
\bibcite{kipf2017semisupervisedclassificationgraphconvolutional}{{2}{2017}{{Kipf and Welling}}{{}}}
\bibcite{reimers-2019-sentence-bert}{{3}{2019}{{Reimers and Gurevych}}{{}}}
\bibcite{vaswani2023attentionneed}{{4}{2023}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{veličković2018graphattentionnetworks}{{5}{2018}{{Veličković et~al.}}{{Veličković, Cucurull, Casanova, Romero, Liò, and Bengio}}}
\bibcite{wang2020minilmdeepselfattentiondistillation}{{6}{2020}{{Wang et~al.}}{{Wang, Wei, Dong, Bao, Yang, and Zhou}}}
\gdef \@abspage@last{9}
